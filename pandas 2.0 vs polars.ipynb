{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the performance of various operations using Pandas and Polars libraries in Python concerning the time taken. These libraries play a critical role in data analysis for mid-sized datasets, where the speed of task completion is of utmost importance while maintaining flexibility and ease of use.\n",
    "\n",
    "For the tasks below, a public dataset from https://grouplens.org/datasets/movielens/ is utilized, containing approximately 25 million rows and having a data size of 662,365KB in raw text format. The dataset consists of columns such as userId, movieId, rating, and timestamp.\n",
    "\n",
    "The \"userId\" field contains 162,541 unique entries, and the \"movieId\" field contains 59,047 unique movies. The \"rating\" column indicates user feedback on a scale of 1 to 5 for the corresponding movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gzip\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions \n",
    "Used to perform tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDayOfWeek(ratingTimestamp):\n",
    "    return datetime.datetime.fromtimestamp(ratingTimestamp).weekday()\n",
    "\n",
    "def percent_changes(pd_time,pl_time):\n",
    "    return round((pl_time-pd_time)/pl_time*100,2)\n",
    "\n",
    "def timeTaken(statTime):\n",
    "    return round(time.time() - startTime,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsDict = {}\n",
    "\n",
    "statsList = [\"readTime\",\"rawWriteTime\",\"zipWriteTime\",\"parquetWriteTime\",\"describeTime\",\"groupbyTime\",\"filterTime\",\"transfromTime\"]\n",
    "\n",
    "for stats in statsList:\n",
    "    statsDict[stats] = {\"pd_\"+stats:\"\",\"pl_\"+stats:\"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "df_pd = pd.read_csv(\"./ml-25m/ml-25m/ratings.csv\",engine=\"pyarrow\")\n",
    "statsDict[\"readTime\"][\"pd_readTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "df_pl = pl.read_csv(\"./ml-25m/ml-25m/ratings.csv\")\n",
    "statsDict[\"readTime\"][\"pl_readTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to raw csv format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "df_pd.to_csv(\"test_pd.csv\",index=False)\n",
    "statsDict[\"rawWriteTime\"][\"pd_rawWriteTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "df_pl.write_csv(\"test_pl.csv\")\n",
    "statsDict[\"rawWriteTime\"][\"pl_rawWriteTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to parquet format with snapp compression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "df_pd.to_parquet(\"test_pd.parquet\",compression=\"snappy\")\n",
    "statsDict[\"parquetWriteTime\"][\"pd_parquetWriteTime\"] = timeTaken(startTime)\n",
    "\n",
    "startTime = time.time()\n",
    "df_pl.write_parquet(\"test_pl.parquet\",compression=\"snappy\")\n",
    "statsDict[\"parquetWriteTime\"][\"pl_parquetWriteTime\"] = timeTaken(startTime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to csv using gzip compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "df_pd.to_csv(\"test_pd.csv.gz\",index=False,compression=\"gzip\")\n",
    "statsDict[\"zipWriteTime\"][\"pd_zipWriteTime\"] = timeTaken(startTime)\n",
    "\n",
    "startTime = time.time()\n",
    "with gzip.open(\"test_pl.csv.gzip\", 'wb') as f:\n",
    "    df_pl.write_csv(f)\n",
    "statsDict[\"zipWriteTime\"][\"pl_zipWriteTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running describe \n",
    "Describe is used quite heavly when performing explorotary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "df_pd.describe()\n",
    "statsDict[\"describeTime\"][\"pd_describeTime\"] = timeTaken(startTime)\n",
    "\n",
    "startTime = time.time()\n",
    "df_pl.describe()\n",
    "statsDict[\"describeTime\"][\"pl_describeTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Groupby \n",
    "\n",
    "Generating aggregate to understand frequency of ratings provided by each users along with min and max ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "tmp_df_pd = df_pd.groupby(\"userId\")[\"rating\"].agg({\"count\",\"min\",\"max\"})\n",
    "statsDict[\"groupbyTime\"][\"pd_groupbyTime\"] = timeTaken(startTime)\n",
    "\n",
    "startTime = time.time()\n",
    "tmp_df_pl = df_pl.groupby(\"userId\").agg(\n",
    "    pl.count(\"rating\").alias(\"count\"),\n",
    "    pl.col(\"rating\").min().alias(\"min\"),\n",
    "    pl.col(\"rating\").max().alias(\"max\")\n",
    ").sort(\"userId\", descending=False)\n",
    "statsDict[\"groupbyTime\"][\"pl_groupbyTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_pd  =tmp_df_pd[[\"count\",\"min\",\"max\"]]\n",
    "tmp_df_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Movie rating dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "tmp_df_pd = df_pd[df_pd[\"rating\"] >= 4 ]\n",
    "statsDict[\"filterTime\"][\"pd_filterTime\"] = timeTaken(startTime)\n",
    "\n",
    "startTime = time.time()\n",
    "tmp_df_pl = df_pl.filter(pl.col(\"rating\") >= 4 )\n",
    "statsDict[\"filterTime\"][\"pl_filterTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of dataset after filtering: \\nLength with Polars:{}\\nLength with Pandas:{}\".format(len(tmp_df_pl),len(tmp_df_pd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming \n",
    "\n",
    "Apply a custom function to a column converting timestamp in seconds to day of week in integer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "startTime = time.time()\n",
    "df_pd[\"WeekDayOfRating\"] = df_pd[\"timestamp\"].apply(lambda x : getDayOfWeek(x))\n",
    "statsDict[\"transfromTime\"][\"pd_transfromTime\"] = timeTaken(startTime)\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "df_pl=df_pl.with_columns([(pl.col(\"timestamp\").apply(lambda x: getDayOfWeek(x)).alias('WeekDayOfRating'))])\n",
    "statsDict[\"transfromTime\"][\"pl_transfromTime\"] = timeTaken(startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_runtimes(statsDict, exclude=\"rawWrite\"):\n",
    "    pandas_times = {}\n",
    "    polars_times = {}\n",
    "    for key in statsDict.keys():\n",
    "        for module in statsDict[key].keys():\n",
    "            tmp =  module.replace(\"Time\",\"\").split(\"_\")\n",
    "            if(exclude not in tmp):\n",
    "                if(\"pd\" in module):pandas_times[tmp[1]] = statsDict[key][module]\n",
    "                elif(\"pl\" in module):polars_times[tmp[1]] = statsDict[key][module]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2,ncols=1,figsize=(12, 10))\n",
    "\n",
    "  # Setting the title and labels for the graph\n",
    "    ax[0].set_title(\"Compare time taken for tasks using Pandas and Polars\")\n",
    "    ax[0].set_xlabel(\"Tasks\")\n",
    "    ax[0].set_ylabel(\"Time (Seconds)\")\n",
    "\n",
    "  # Creating a bar graph for Pandas and Polars runtimes\n",
    "    operations = pandas_times.keys()\n",
    "    num_operations = len(operations)\n",
    "    bar_width = 0.35\n",
    "    pandas_x = np.arange(num_operations)\n",
    "    polars_x = pandas_x + bar_width\n",
    "\n",
    "    pandas_y = list(pandas_times.values())\n",
    "    polars_y = list(polars_times.values())\n",
    "\n",
    "    pandas_bar = ax[0].bar(pandas_x, pandas_y, bar_width, color='tab:blue', label='Pandas')\n",
    "    polars_bar = ax[0].bar(polars_x, polars_y, bar_width, color='tab:orange', label='Polars')\n",
    "\n",
    "  # Setting the x-axis ticks and labels\n",
    "    ax[0].set_xticks(pandas_x + bar_width / 2)\n",
    "    ax[0].set_xticklabels(operations)\n",
    "\n",
    "  # Setting the y-axis limit as the maximum of the two maximum values of runtimes\n",
    "    ax[0].set_ylim(0, max(max(pandas_y), max(polars_y)) * 1.2)\n",
    "\n",
    "  # Adding values on top of the bars\n",
    "    for i, bars in enumerate(zip(pandas_bar, polars_bar)):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax[0].annotate(f\"{height:.2f}\", xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                  xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "  # Adding a legend to the graph\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].set_title(\"Percentage Time Reduced with Polars compared to Pandas\")\n",
    "    ax[1].set_xlabel(\"Tasks\")\n",
    "    ax[1].set_ylabel(\"Percentage Time Reduced\")\n",
    "    \n",
    "    percents = []\n",
    "    for pd_operationTime, pl_operationTime in zip(pandas_y,polars_y):\n",
    "        percents.append(percent_changes(pd_operationTime,pl_operationTime))\n",
    "\n",
    "    bars = ax[1].bar(pandas_x, percents, bar_width, color='tab:blue')\n",
    "    ax[1].set_xticks(pandas_x + bar_width / 2)\n",
    "    ax[1].set_xticklabels(operations)\n",
    "    ax[1].set_ylim(0, min(min(percents), min(percents)) * 1.2)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax[1].annotate(f\"{height:.2f}%\", xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                  xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "    \n",
    "  # Displaying the graph\n",
    "#     fig.tight_layout()\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_runtimes(statsDict,exclude=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_runtimes(statsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
